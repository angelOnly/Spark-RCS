## 4.3 为所有用户做推荐并持久化存储
为所有用户预测推荐结果，并取出前 5 个存到数据库

1. 获取所有用户的 userid
2. 加载训练效果最好的模型
3. 获取用户的推荐结果并取前 5 个
4. 将推荐结果转成 DataFrame
5. 将 DataFrame 写入数据库


**AppConf**
```
trait AppConf {
  val localClusterURL = "local[2]"
  val clusterMasterURL = "spark://master:7077"
  val conf = new SparkConf().setMaster(clusterMasterURL)
  val sc = new SparkContext(conf)
  val sqlContext = new SQLContext(sc)
  val hc = new HiveContext(sc)

  //jdbc连接
  val jdbcURL = "jdbc:mysql://master:3306/hive_db"
  val recResultTable = "hive_db.user_movie_recommandation"
  val mysqlusername = "root"
  val mysqlpassword = "Training@1"
  val prop = new Properties
  prop.put("driver", "com.mysql.jdbc.Driver")
  prop.put("user", mysqlusername)
  prop.put("password", mysqlpassword)
}

```

**RecommendForAllUsers**
```scala
package xiaoli.com.ml

import org.apache.spark._
import org.apache.spark.mllib.recommendation._
import org.apache.spark.sql._
import xiaoli.com.caseclass._
import xiaoli.com.conf._

object RecommendForAllUsers extends AppConf {
  //在集群中提交这个main进行运行的时候，需要通过--jars来把mysql的驱动jar包所在的路径添加到classpath
  //按照pom.xml中指定的版本，安装hbase1.2.6以及phoenix4.9
  //如果需要写入到Phoenix,则也需要添加一些相关的jar包添加到classpath
  //通过maven assembly:assembly的方式打成jar包，然后在集群中运行
  def main(args: Array[String]) {

    /**
      * 1. 获取所有用户 userid
      */
    val users = hc.sql("select distinct(userId) from trainingData order by userId asc")
    val allusers = users.rdd.map(_.getInt(0)).toLocalIterator

    //方法1，可行，但是效率不高

    //1.为所有用户的每部电影没有打分的进行预测，即将稀疏矩阵打分填满
    //2.为每个用户的打分进行倒序排序，高分 -> 低分
    //3.为每个用户取出对应行的前5个元素

    /**
      * 两种方法的根本区别在于内存。
      * 第一种方法，虽然效率不高，但是每次只需要计算一个用户的推荐结果，然后进行排序，将前 5 个结果存到 sql 中。
      * 当第一个用户的计算结果存入以后，就会将其中占用的内存清除，不会保存。
      *
      * 第二种方式。
      * 是将所有用户的推荐结果全部载入内存中切分成 partition，然后同时对每个 partition 进行计算。
      * 如果有 10w 个用户的话，每个 executor 可能分配 1w 行数据。
      * 同时在这个 executor 中进行排序，计算拿出前面 5 个。
      *
      * 这种方式虽然运算速度快，但是所需要的内存相较于第一种方式可能需要数万倍。
      * 同时开始计算并且是分布式的，如果内存足够大的话，那么没问题。
      *
      * 但是这是一个笛卡尔积的矩阵计算，做完笛卡尔积，还要进行排序取出前 5 个，需要的内存是非常大的。
      *
      * 当调用第二种方式，即使只是取出一条数据的推荐结果，也会报 OOM。
      */


    /**
      * 2. 加载模型
       */
    val modelpath = "/tmp/bestmodel/0.8215454233270015"
    val model = MatrixFactorizationModel.load(sc, modelpath)

    while (allusers.hasNext) {
      //每次只为一个用户预测打分写到数据库
      /**
        * 3. 获得推荐列表，取得前 5 个
        */
      val rec = model.recommendProducts(allusers.next(), 5)

      writeRecResultToMysql(rec, sqlContext, sc)
//            writeRecResultToHbase(rec, sqlContext, sc)
    }

    //方法2，不可行
    // 这一种方法是将所有用户都计算预测的打分
    //    val recResult = model.recommendProductsForUsers(5)

    def writeRecResultToMysql(uid: Array[Rating], sqlContext: SQLContext, sc: SparkContext) {
      val uidString = uid.map(x => x.user.toString() + "|"
        + x.product.toString() + "|" + x.rating.toString())

      /**
        * 4. 将结果转成 DF
        */
      import sqlContext.implicits._
      val uidDFArray = sc.parallelize(uidString)
      val uidDF = uidDFArray.map(_.split("|")).map(x => Result(x(0).trim().toInt, x(1).trim.toInt, x(2).trim().toDouble)).toDF

      /**
        * 5. 将DF写入数据库中
        */
      uidDF.write.mode(SaveMode.Overwrite).jdbc(jdbcURL, recResultTable, prop)
    }

    //把推荐结果写入到phoenix+hbase,通过DF操作，不推荐。
    val hbaseConnectionString = "localhost"
    val userTupleRDD = users.rdd.map { x => Tuple3(x.getInt(0), x.getInt(1), x.getDouble(2)) }
    userTupleRDD.saveToPhoenix("NGINXLOG_P", Seq("USERID", "MOVIEID", "RATING"), zkUrl = Some(hbaseConnectionString))

    //把推荐结果写入到phoenix+hbase,通过DF操作，不推荐。
    def writeRecResultToHbase(uid: Array[Rating], sqlContext: SQLContext, sc: SparkContext) {
      val uidString = uid.map(x => x.user.toString() + "|"
        + x.product.toString() + "|" + x.rating.toString())
      import sqlContext.implicits._
      val uidDF = sc.parallelize(uidString).map(_.split("|")).map(x => Result(x(0).trim().toInt, x(1).trim.toInt, x(2).trim().toDouble)).toDF
      //zkUrl需要大家按照自己的hbase配置的zookeeper的url来设置
      uidDF.save("org.apache.phoenix.spark", SaveMode.Overwrite, Map("table" -> "phoenix_rec", "zkUrl" -> "localhost:2181"))
    }
  }
}

```

### 难点

**两种方式都做了以下三件事**

1. 为所有用户的每部电影没有打分的进行预测，即将稀疏矩阵打分填满
2. 为每个用户的打分进行倒序排序，高分 -> 低分
3. 为每个用户取出对应行的前5个元素



第一种方式，每次只对一个用户预测的 rating 排序选出前 5 个推荐结果写入数据库

**可行，效率低下**

````scala
val allusers = users.rdd.map(_.getInt(0)).toLocalIterator
while (allusers.hasNext) {
    //每次只为一个用户预测打分写到数据库
    val rec = model.recommendProducts(allusers.next(), 5)
    writeRecResultToMysql(rec, sqlContext, sc)
}
````

第二种方式，一次性计算出全部用户的 rating 结果，再进行排序存入数据库

**不可行，占用内存太大，以至于 OOM**

````scala
val recResult = model.recommendProductsForUsers(5)
````

#### 原因

>**两种方式的根本区别在于 内存。**
>
>**第一种**
>
>- 第一种方法，虽然效率不高，但是每次只需要计算一个用户的推荐结果，然后进行排序，将前 5 个结果存到 sql 中。
>- 当第一个用户的计算结果存入以后，就会将其中占用的内存清除，不会保存。
>
>**第二种**
>
>- 是将所有用户的推荐结果全部载入内存中切分成 partition，然后同时对每个 partition 进行计算。
>- 如果有 10w 个用户的话，每个 executor 可能分配 1w 行数据。
>- 同时在这个 executor 中进行排序，计算拿出前面 5 个。
>- 这种方式虽然运算速度快，但是所需要的内存相较于第一种方式可能需要数万倍。
>- 同时开始计算并且是分布式的，如果内存足够大的话，那么没问题。
>- 但是这是一个笛卡尔积的矩阵计算，做完笛卡尔积，还要进行排序取出前 5 个，需要的内存是非常大的。
>- 当调用第二种方式，即使只是取出一条数据的推荐结果，也会报 OOM。
