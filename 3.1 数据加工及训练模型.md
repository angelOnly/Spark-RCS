## 3.1 数据加工及训练模型

将数据集转换成 ALS 格式的 RDD 数据集。

[org.apache.spark.mllib.recommendation.ALS](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.recommendation.ALS$)

**def train(ratings: RDD[Rating]], rank: Int, iterations: Int, lambda: Double, blocks: Int, seed: Long): MatrixFactorizationModel**

Train a matrix factorization model given an RDD of ratings by users for a subset of products. The ratings matrix is approximated as the product of two lower-rank matrices of a given rank (number of features). To solve for these features, ALS is run iteratively with a configurable level of parallelism.

- ratings

  RDD of [Rating](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/mllib/recommendation/Rating.html) objects with userID, productID, and rating

- rank

  number of features to use (also referred to as the number of latent factors)

- iterations

  number of iterations of ALS

- lambda

  regularization parameter

- blocks

  level of parallelism to split computation into

- seed

  random seed for initial matrix factorization model

### 划分训练集和测试集

````scala
val localClusterURL = "local[2]"
val clusterMasterURL = "spark://master:7077"
val conf = new SparkConf().setAppName("ETL").setMaster(clusterMasterURL)
val sc = new SparkContext(conf)
val sqlContext = new SQLContext(sc)
val hc = new HiveContext(sc)

//RDD[Rating]需要从原始表中提取 userid,movieid,rating 数据
//并把这些数据切分成训练集和测试集数据
val ratings = hc.sql("cache table ratings")
val count = hc.sql("select count(*) from ratings").first().getLong(0).toInt
val percent = 0.6
val trainingdatacount = (count * percent).toInt //12973312
val testdatacount = (count * (1 - percent)).toInt
````

### 将训练集和测试集倒序排序存储

````scala
//order by asc
val trainingDataAsc = hc.sql(s"select userId,movieId,rating from ratings order by timestamp asc")
trainingDataAsc.write.mode(SaveMode.Overwrite).parquet("/tmp/trainingDataAsc")
hc.sql("drop table if exists trainingDataAsc")
hc.sql("create table if not exists trainingDataAsc(userId int,movieId int,rating double) stored as parquet")
hc.sql("load data inpath '/tmp/trainingDataAsc' overwrite into table trainingDataAsc")

val trainingDataDesc = hc.sql(s"select userId,movieId,rating from ratings order by timestamp desc")
trainingDataDesc.write.mode(SaveMode.Overwrite).parquet("/tmp/trainingDataDesc")
hc.sql("drop table if exists trainingDataDesc")
hc.sql("create table if not exists trainingDataDesc(userId int,movieId int,ratings double) stored as parquet")
hc.sql("load data inpath '/tmp/trainingDataDesc' overwrite into table trainingDataDesc")

// limit
val trainingData = hc.sql(s"select * from trainingDataAsc limit $trainingdatacount")
trainingData.write.mode(SaveMode.Overwrite).parquet("/tmp/trainingData")
hc.sql("drop table if exists trainingData")
hc.sql("create table if not exists trainingData(userId int,movieId int,rating double) stored as parquet")
hc.sql("load data inpath '/tmp/trainingData' overwrite into table trainingData")

val testData = hc.sql(s"select * from trainingDataDesc limit $testdatacount")
testData.write.mode(SaveMode.Overwrite).parquet("/tmp/testData")
hc.sql("drop table if exists testData")
hc.sql("create table if not exists testData(userId int,movieId int,rating double) stored as parquet")
hc.sql("load data inpath '/tmp/testData' overwrite into table testData")
````

> **思考**
>
> ```scala
> val trainingDataAsc = hc.sql(s"select userId,movieId,rating from ratings order by timestamp asc limit $trainingdatacount")
> ```
> order by limit 的时候，需要注意 OOM 的问题，因为 trainingdatacount 太大。
>
> 原因：
>
> 这句 SQL 做了两个操作
>
> 1. 按照 timestamp 进行 order by
> 2. 根据 trainingdatacount 进行 limit，取出数据，这是很耗时的操作，因为 limit 很大，又是全表扫描，所以很耗时
>
> 解决：
>
> 将 order by 和 limit 分开做。先做 order by 进行降序排列，再进行 limit 操作
>
> ````scala
> val trainingDataAsc = hc.sql(s"select userId,movieId,rating from ratings order by timestamp asc")
> val trainingData = hc.sql(s"select * from trainingDataAsc limit $trainingdatacount")
> ````

### 训练模型

```scala
//转成 RatingRDD 格式，然后进行训练
val ratingRDD = hc.sql("select * from trainingData").rdd.map(x => Rating(x.getInt(0),x.getInt(1),x.getDouble(2)))
    
val model = ALS.train(ratingRDD, 1, 10)
```

